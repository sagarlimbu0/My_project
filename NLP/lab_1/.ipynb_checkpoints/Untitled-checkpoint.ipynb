{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading the LABS of cit480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "files= os.listdir(r'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab.txt\n"
     ]
    }
   ],
   "source": [
    "for i in files:\n",
    "    if i.endswith('.txt'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, reading a random lab file for cit480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lab.txt', \"r\") as f:\n",
    "    rand_lab= f.read().replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using TOKENIZATION from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'lab',\n",
       " 'is',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'introduce',\n",
       " 'you',\n",
       " 'to',\n",
       " 'Ansible',\n",
       " 'Configuration']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_tokenize= word_tokenize(rand_lab)\n",
    "lab_tokenize[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Library: FREQUENCY Dsitribution\n",
    "from nltk import FreqDist\n",
    "\n",
    "# creating instance\n",
    "freq_dist= FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting each strings into LOWERCASE\n",
    "for i in lab_tokenize:\n",
    "    freq_dist[i.lower()] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP 6 MOST COMMON words used on the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('*', 461),\n",
       " (':', 56),\n",
       " ('ansible', 28),\n",
       " ('to', 24),\n",
       " ('|', 23),\n",
       " ('a', 21),\n",
       " ('the', 17),\n",
       " ('playbook', 15),\n",
       " ('.', 13),\n",
       " ('and', 12)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the sentence by seperating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams, bigrams, trigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after perfroming TOKENIZATION, we can use the above libraries\n",
    "# to seperate sentecnes into Consecutive words that can yeild different meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'lab'),\n",
       " ('lab', 'is'),\n",
       " ('is', 'designed'),\n",
       " ('designed', 'to'),\n",
       " ('to', 'introduce')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BIGRAMS\n",
    "\n",
    "lab_bigrams= list(bigrams(lab_tokenize))\n",
    "lab_bigrams[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'lab', 'is'),\n",
       " ('lab', 'is', 'designed'),\n",
       " ('is', 'designed', 'to'),\n",
       " ('designed', 'to', 'introduce'),\n",
       " ('to', 'introduce', 'you')]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_trigrams= list(trigrams(lab_tokenize))\n",
    "lab_trigrams[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('introduce', 'you', 'to', 'Ansible', 'Configuration'),\n",
       " ('you', 'to', 'Ansible', 'Configuration', 'Management'),\n",
       " ('to', 'Ansible', 'Configuration', 'Management', '.'),\n",
       " ('Ansible', 'Configuration', 'Management', '.', 'Sticking'),\n",
       " ('Configuration', 'Management', '.', 'Sticking', 'with'),\n",
       " ('Management', '.', 'Sticking', 'with', 'the'),\n",
       " ('.', 'Sticking', 'with', 'the', 'theme'),\n",
       " ('Sticking', 'with', 'the', 'theme', 'wewill'),\n",
       " ('with', 'the', 'theme', 'wewill', 'be'),\n",
       " ('the', 'theme', 'wewill', 'be', 'using'),\n",
       " ('theme', 'wewill', 'be', 'using', 'Ansible')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NGRAMS\n",
    "lab_ngrams= list(ngrams(lab_tokenize, 5))\n",
    "lab_ngrams[5:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string= \"Lets eat, grandpa.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string_token= word_tokenize(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lets', 'eat'), ('eat', ','), (',', 'grandpa'), ('grandpa', '.')]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigrams\n",
    "my_string_bigram= list(bigrams(my_string_token))\n",
    "my_string_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lets', 'eat', ','), ('eat', ',', 'grandpa'), (',', 'grandpa', '.')]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRIGRAMS\n",
    "my_string_trigram= list(trigrams(my_string_token))\n",
    "my_string_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lets',), ('eat',), (',',), ('grandpa',), ('.',)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ngrams\n",
    "my_string_ngram= list(ngrams(my_string_token,1))\n",
    "my_string_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
